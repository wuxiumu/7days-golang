# 爬虫实战
https://wiki.eryajf.net/pages/a0f866/#_1-%E7%99%BE%E5%BA%A6%E8%B4%B4%E5%90%A7%E5%B0%8F%E7%88%AC%E8%99%AB
## 实战项目
### 豆瓣电影Top250
#### 目标
爬取豆瓣电影Top250的电影名称、评分、评价人数、导演、编剧、主演、类型、上映时间、片长、海报等信息。
#### 步骤
1. 确定爬取的网站：豆瓣电影Top250
2. 分析网站结构：电影信息都在列表页，每部电影的信息都在一个item中，因此可以直接使用列表页的URL进行爬取。
3. 确定爬取的字段：电影名称、评分、评价人数、导演、编剧、主演、类型、上映时间、片长、海报等信息。
4. 编写爬虫代码：使用Python的requests、BeautifulSoup、lxml库进行爬取。
5. 保存数据：使用csv或json格式保存爬取的数据。
6. 分析数据：对爬取的数据进行分析，找出有意思的东西。
7. 部署爬虫：将爬虫部署到服务器上，定时运行，定时更新数据。

```go
import requests
from bs4 import BeautifulSoup
import csv

# 豆瓣电影Top250的URL
url = 'https://movie.douban.com/top250'

# 发送请求获取网页内容
response = requests.get(url)

# 解析网页内容
soup = BeautifulSoup(response.text, 'lxml')

# 找到所有电影item
items = soup.find_all('div', class_='item')

# 定义一个列表，用于保存爬取的数据
data = []

# 遍历所有电影item
for item in items:
    # 电影名称
    title = item.find('span', class_='title').text.strip()
    # 评分
    rating = item.find('span', class_='rating_num').text.strip()
    # 评价人数
    votes = item.find('span', class_='inq').text.strip().split()[0]
    # 导演
    directors = [a.text.strip() for a in item.find_all('a', rel='v:directedBy')]
    # 编剧
    screenwriters = [a.text.strip() for a in item.find_all('a', rel='v:starring')]
    # 主演
    actors = [a.text.strip() for a in item.find_all('a', rel='v:starring')]
    # 类型
    types = [a.text.strip() for a in item.find_all('span', property='v:genre')]
    # 上映时间
    release_date = item.find('span', property='v:initialReleaseDate').text.strip()
    # 片长
    runtime = item.find('span', property='v:runtime').text.strip()
    # 海报
    poster = item.find('img')['src']
    # 将爬取的数据保存到列表中
    data.append([title, rating, votes, directors, screenwriters, actors, types, release_date, runtime, poster])

# 保存数据到csv文件
with open('douban_top250.csv', 'w', newline='', encoding='utf-8') as f:
    writer = csv.writer(f)
    writer.writerow(['电影名称', '评分', '评价人数', '导演', '编剧', '主演', '类型', '上映时间', '片长', '海报'])
    writer.writerows(data)
```
